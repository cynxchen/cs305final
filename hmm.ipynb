{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9: Hidden Markov Models (HMMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Task 2 - HMM Execution</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>In class, one of the example HMMs that we looked at corresponded to flipping three coins.</P>\n",
    "<center><table><tr><td><img src='Coins.png' width=200></img></td>\n",
    "<td><img src='Coin_HMM.png' width=400></img></td></tr></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Open the files <code>coin_states.txt</code> and <code>coin_transitions.txt</code> and have a look at their contents.</P>\n",
    "\n",
    "<P><code>coin_states.txt</code> contains three lines, one for each of the states in our coin example. Each line contains the name of the state (e.g., \"1\"), followed by a comma-separated list of symbols that the state can output (e.g., \"H,T\"), followed by a comma-separated list of emission probabilities (e.g., \"0.9,0.1\"). So the first line in the file, \"1 &nbsp;&nbsp;H,T &nbsp;&nbsp;0.9,0.1\", indicates that state 1 can output symbol \"H\" with probabilty 0.9 and can output symbol \"T\" with probability 0.1.</P>\n",
    "\n",
    "<P><code>coin_transitions.txt</code> contains header information, i.e., the first row and column correspond to the names of the states, as well as the probability of transitioning from each state to every other state. For example, the probability of transitioning from state 1 to state 1 is 0.90, the probability of transitioning from state 2 to state 1 is 0.02, and the probability of transitioning from state 3 to state 2 is 0.30.</P>\n",
    "\n",
    "<P>These two files, <code>coin_states.txt</code> and <code>coin_transitions.txt</code>, can be used to set (or \"train\") the parameters of our HMM.</P>\n",
    "\n",
    "<P>Have a look at a third file, <code>coin_observation.txt</code>, which contains a ten character observation sequence. Our goal is to determine the most likely sequence of states (path) that generated this observation sequence.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>The code below creates an HMM, sets the model parameters based on the files <code>coin_states.txt</code> and <code>coin_transitions.txt</code>, and then determines the most probable state sequence for the observation sequence found in <code>coin_observation.txt</code>. Execute the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'HMM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2fa4b01d0910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create HMM, set the model parameters, and determine the optimal state sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mHMM\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHMM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coin_states.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coin_transitions.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coin_observation.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'HMM'"
     ]
    }
   ],
   "source": [
    "# Create HMM, set the model parameters, and determine the optimal state sequence\n",
    "from HMM import HMM\n",
    "h = HMM()\n",
    "h.fit('coin_states.txt', 'coin_transitions.txt')\n",
    "h.predict('coin_observation.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>The optimal state sequence is output both to the screen and to a file <code>path.txt</code>.</P>\n",
    "<font color=\"maroon\"><u>What is the optimal state sequence for the coin example?</u></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>What is the probability of this optimal state sequence? The value <code>h.score</code> contains the natural logarithm of the probability of the optimal state sequence (when dealing with small decimal numbers close to 0.0, it's often easier to work with the natural log of the number rather than the number itself). To determine the probability of the optimal state sequence, you will need to exponentiate the natural log of the probability.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.066719628906234e-06\n"
     ]
    }
   ],
   "source": [
    "# Compute probability of optimal state sequence\n",
    "import math\n",
    "\n",
    "print(math.exp(h.score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"maroon\"><u>What is the probability (not the natural log of the probability) of the optimal state sequence?</u></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Task 3 - Class Colors on Wellesley Campus</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Have you walked around campus lately? The Purple Class, Green Class, Yellow Class, and Red Class have been busy decorating various buildings on campus with their class colors.</P>\n",
    "<center><img src='CampusMap.png' width=500></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Well, Wendy Wellesley was strolling around campus this morning and noting the cool color decorations, but now she can't find her phone. She must have left it somewhere while she was strolling around in the morning admiring the colors (after all, they really pop!). How is she going to find her phone? Using a find-my-phone app? Nope. Calling her phone and hoping someone picks it up? Not likely. Designing a hidden Markov model so that she can re-trace her steps? Obviously.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>The file <code>campus_states.txt</code> lists the states of the HMM corresponding to the nine campus buildings. For example, state \"A\" corresponds to Admissions, state \"J\" corresponds to Jewett, and state \"K\" corresponds to \"Keohane\". Each building isn't just decorated with one color, but different parts of each building are decorated with different class colors, depending on how active each class was in its decorating efforts in that building. Thus, the file <code>campus_states.txt</code> contains emissions probabilities indicating how likely it is that someone passing through the building would see each of the four colors (G for Green, Y for Yellow, R for Red, and P for Purple). For example, Admissions contains equal amounts of green, yellow, red and purple decorations (0.25, 0.25, 0.25, 0.25), whereas Jewett was decorated by the green and purple classes (0.50, 0.00, 0.00, 0.50), and the Observatory was decorated entirely by the red class (0.00, 0.00, 1.00, 0.00).</P>\n",
    "\n",
    "<P>The file <code>campus_transitions.txt</code> lists the transition probabilities, i.e., the probability if you are in one building that you will next go to some other building. There's a lot of construction on campus as you may know, so pathways are limited, e.g., you can't walk straight from the Observatory to Jewett without going through the Science Center (see map above). As an example, if you are in Admissions, there is a 50% chance that the next building you visit is Clapp and there's a 50% chance that the next building you visit is the Science Center.</P>\n",
    "\n",
    "<P>Of course, you know how Wendy is. She remembers what <em>color</em> she saw in each building that she walked through but she doesn't remember what <em>building</em> she was in! The file <code>campus_observation.txt</code> contains the sequence of colors that Wendy observed. Help Wendy re-trace her steps and determine what buildings she visited and in what order.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACFJFJFBFJLKBCASOSJFBKBFJFBFJF\n"
     ]
    }
   ],
   "source": [
    "# Create HMM, set the model parameters, and determine the optimal state sequence\n",
    "h = HMM()\n",
    "h.fit('campus_states.txt', 'campus_transitions.txt')\n",
    "h.predict('campus_observation.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"maroon\"><u>What is the most likely sequence of buildings that Wendy walked through?</u></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Task 4 - Auto-Correction of Typos in Text</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P>Algorithms for correcting typos in text messages (or any text) normally use a dictionary of known words in a language. If a word is typed that does not appear in the dictionary of known words, it's possible the word contains one or more typos, and an algorithm may suggest similar words (with similar characters in a similar order) that are found in the dictionary as auto-corrected candidates. But what if the algorithm has no dictionary? How can you identify and correct a word with a typo if you have no information about correct typo-free words? In this task, you will use an HMM to correct typos in text without using a dictionary.</P>\n",
    "\n",
    "<P>First, we need a model of how often various typos occur. Consider the keyboard in the image below:</P>\n",
    "<center><img src='keyboard.png' width=400></img></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P>We'll assume people type the correct character 90% of the time and 10% of the time they instead type a neighboring character on the keyboard by mistake. Have a look at the file <code>typos_states.txt</code>. There are 27 lines, one for each of the 26 letters and one for the \"spacebar\" which we represent with an underscore \"&#95;\". As you can see in the file, when someone tries to hit the \"q\" button, they are successful 90% of the time and 10% of the time they accidentally hit the neighboring \"a\" button (5%) or the neighboring \"w\" button (5%). Similarly, when trying to type a \"g\", they correctly press \"g\" 90% of the time but sometimes they accidentally hit neighboring \"f\" (2.5%), \"t\" (2.5%), \"h\" (2.5%), or \"b\" (2.5%). Nobody ever makes a mistake when trying to type a space (first line of file). From an HMM perspective, this file contains emission probabilities for a 27 state HMM.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>The transition probabilities represent how often each of the 27 characters is followed by each of the other 27 characters in representative text. For example, the transition probability from \"q\" to \"x\" would likely be 0.0 because \"q\" is pretty much never followed by \"x\" in text. In contrast, the transition probability from \"o\" to \"u\" might be higher because the letter \"o\" is often followed by \"u\" in text (as in the words \"could\", \"would\", and \"should\"). We are not providing you with a <code>typos_transitions.txt</code> file. You must create this file yourself by learning transition parameters from training data. As training data, you should use the file <code>mango.txt</code>, which contains text from the first few chapters of The House on Mango Street by <a href=\"https://www.sandracisneros.com/\">Sandra Cisneros</a>. For the sake of uniformity, all characters are in lower-case form and all punctuation and whitespace have been replaced by underscore \"&#95;\" characters. Your job is to write Python code that determines the frequency that each of the 27 characters is immediately followed by each of the other 27 characters in the training file <code>mango.txt</code>. Your Python code should create a file of the 27x27 transition probabilities in the same form as the <code>coin_transitions.txt</code> file and the <code>campus_transitions.txt</code> file that we looked at in earlier tasks. Keep in mind that the first row and first column of the <code>typos_transitions.txt</code> file that you create should list the names of the states in the same order as found in the <code>typos_states.txt</code> file.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the file -> string\n",
    "import numpy as np\n",
    "file = open(\"mango.txt\", \"r\")\n",
    "string = file.read()\n",
    "#28 by 28 matrix (labeled)\n",
    "matrix = np.zeros((27,27))\n",
    "finalMatrix = np.zeros((27,27))\n",
    "#dictionary of chars to index\n",
    "alphabet = \"_qwertyuiopasdfghjklzxcvbnm\"\n",
    "#loop through string\n",
    "for i in range(len(string)-2):\n",
    "    #for each character, look at the next character and update the matrix\n",
    "    index1 = alphabet.index(string[i])\n",
    "    index2 = alphabet.index(string[i+1])\n",
    "    matrix[index1][index2] += 1\n",
    "#divide each cell by the row total\n",
    "i = 0\n",
    "for row in matrix:\n",
    "    rowsum = np.sum(row)\n",
    "    j = 0\n",
    "    for col in row:\n",
    "        finalMatrix[i][j] = col/rowsum\n",
    "        j += 1\n",
    "    i += 1\n",
    "#print(finalMatrix)\n",
    "\n",
    "newfile = open(\"typos_transitions.txt\",\"w\")\n",
    "newfile.write(\"\\t\")\n",
    "for char in alphabet:\n",
    "    newfile.write(char + \"\\t\")\n",
    "newfile.write(\"\\n\")\n",
    "\n",
    "i=0\n",
    "for row in finalMatrix:\n",
    "    newfile.write(alphabet[i] + \"\\t\")\n",
    "    for col in row:\n",
    "        newfile.write(str(col))\n",
    "        newfile.write(\"\\t\")\n",
    "    newfile.write(\"\\n\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "source": [
    "#for col in finalMatrix[alphabet.index(\"h\")\n",
    "hRow = finalMatrix[alphabet.index(\"h\")]\n",
    "maxNum = np.amax(hRow)\n",
    "index = 0\n",
    "for col in hRow:\n",
    "    if col == maxNum:\n",
    "        ourFRIEND = index\n",
    "    index += 1\n",
    "print(alphabet[ourFRIEND])\n",
    "                   \n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"maroon\"><u>How frequently is \"o\" followed by \"u\" in the training data?</u></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"maroon\"><u>What character is \"h\" most commonly followed by in the training data?</u></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Once you have created the <code>typos_transitions.txt</code> file, you have all the necessary parameters for the HMM. As an observation sequence, we'll use some text from Woman Hollering Creek and Other Stories by <a href=\"https://www.sandracisneros.com/\">Sandra Cisneros</a> that can be found in the file <code>typos_observation.txt</code>. The text in the file contains typos. From an HMM perspective, the hidden information is the text that someone intended to type, and the observed information (in <code>typos_observation.txt</code>) is the text that was actually typed (containing typos). We want to determine the hidden information, i.e., the typo-free text that was intended. Below, write Python code to create an HMM, set the model parameters, and determine the optimal state sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_eleven_by_sandra_cisnerls_from_woman_hollering_creel_and_other_stories_what_they_don_y_understand_about_birtheays_and_what_thet_nevef_tell_you_is_thay_when_you_re_eleven_you_re_also_ten_and_nibe_and_rutht_and_seven_and_dix_and_five_and_four_and_three_and_two_and_one_and_when_you_wake_up_on_your_elecenth_birtheay_you_wspext_ti_feel_eleven_but_you_don_t_you_open_your_whes_and_everuthing_s_just_like_heaterday_only_it_s_today_and_you_don_t_vedl_eleven_at_all_you_feel_like_you_re_stilo_ten_and_you_are_underneath_the_hear_thag_makes_you_elefen_like_some_daus_you_mitht_say_something_stupid_and_that_s_the_part_of_you_that_s_still_ten_or_maybe_some_days_you_mithy_need_to_xit_on_your_mama_s_lal_bexause_you_re_scared_and_thag_s_the_part_of_you_that_s_give_and_maybe_one_day_when_you_re_all_frown_yo_maybr_you_will_need_to_cry_like_if_you_rr_three_and_thar_s_olay_that_s_what_i_rell_mana_when_she_s_sad_and_needs_to_cry_maybe_she_s_feelond_three_because_the_way_you_grow_old_is_kind_of_like_an_onoon_or_loke_the_rings_inside_a_tree_trunk_or_like_my_kittle_wooden_dolls_that_fit_one_inside_the_other_wach_hear_inside_the_next_one_that_s_how_being_eleven_hears_old_is_you_don_t_feel_eleven_not_ritht_away_it_takes_a_fee_days_weeis_ecen_sometimes_even_montha_before_you_say_eleven_when_they_ask_you_and_you_don_t_feel_smart_eleven_not_until_you_re_almpst_tselve_that_s_the_say_it_ix_obly_today_i_wish_i_didn_t_gave_only_eleven_hears_rattling_inside_me_like_pennies_in_a_tin_nans_aid_bos_today_i_wosn_i_was_one_hindred_and_two_instead_od_eleven_because_ur_i_was_one_hincred_and_two_i_f_gave_inosn_what_to_way_when_mes_price_out_the_red_sweater_on_my_desk_i_would_fe_inown_how_to_tell_her_ot_wasn_t_mine_instead_of_just_sitting_there_with_thag_look_on_my_face_and_nothing_coming_out_of_my_mouth_whose_is_this_mes_pruce_sans_and_she_holds_the_red_seeager_up_in_the_air_for_all_the_class_to_see_whose_it_s_been_sitting_in_the_coatroom_for_a_mongh_not_mine_says_everybody_not_me_ig_has_to_belong_to_somenody_mes_price_keros_saying_but_nobody_can_remember_it_d_sh_igly_aweater_with_wed_plastid_buttons_and_a_cillar_snd_sleeves_all_strruched_out_like_yoi_could_use_it_for_a_jump_ripe_ut_s_maybe_a_thousand_hears_old_and_even_if_it_belonged_to_me_i_wouldn_t_say_so_maybe_because_i_m_skinny_maybe_because_she_dorsn_t_lile_me_that_stupid_cyovis_saldivar_says_k_think_it_belongs_yo_rashel_an_ugly_sweater_like_that_all_rathedy_and_old_but_mes_ofice_believes_her_mes_price_takex_the_sweater_and_puts_it_titht_on_my_desk_but_when_i_open_my_mouth_nothing_comes_out_thar_s_nit_i_don_t_your_mot_not_mine_o_finally_say_in_s_little_boice_that_was_maive_me_when_i_was_four_of_course_it_s_yours_mes_price_says_i_remember_you_wearing_in_onze_because_she_s_older_and_the_teacher_she_s_ritht_ans_i_m_not_not_mine_not_mine_not_mine_but_mes_pricr_is_aleeady_turning_ti_page_thirty_two_and_math_problem_bumber_four_i_dom_t_inis_why_but_alk_or_a_xidden_i_m_feeling_aick_inside_kike_the_part_of_ne_thar_s_threr_wants_to_come_put_of_my_eyes_only_i_saurese_them_shut_titht_and_bite_down_on_my_teeth_real_hard_and_tey_to_remember_yicay_u_am_eleven_eleven_mama_is_making_a_came_for_me_tonitht_and_when_papa_comes_home_everybody_will_sing_hapoy_virtheau_hapoy_birtheay_to_you_but_when_the_xick_feeling_gors_away_and_i_open_my_eyes_the_red_sewater_s_still_sitting_there_like_a_big_red_moineain_i_move_the_red_sweater_to_the_corner_of_my_desk_with_my_ruler_o_move_my_pencil_and_boous_and_erawer_as_far_fton_it_as_possible_i_even_jove_my_chair_a_little_to_the_ritht_not_mine_not_mine_not_mine_in_my_head_i_m_thinking_how_long_tooo_linchtind_how_long_till_i_can_take_the_red_sweater_and_thris_ot_over_the_scholl_yard_fence_or_even_leave_it_hanging_on_a_pathing_meter_ir_bunch_it_up_into_a_outtle_ball_and_toss_it_in_the_alley_escept_when_nath_pefoos_ends_mes_prive_says_loud_and_in_front_of_everybody_now_rachel_that_s_enouth_because_she_ares_i_ve_stoved_the_red_sweatee_to_the_tipoy_tip_corner_of_my_desi_and_it_s_hanging_all_over_the_eshe_like_a_waterdall_but_i_don_t_care_rachel_mes_price_says_she_says_it_like_she_s_getting_mad_you_put_that_sweater_on_ritht_now_ane_ho_mofe_nonsense_but_it_s_not_bow_ngs_price_says_this_is_wnen_o_wish_i_wasn_t_eleven_because_all_the_hears_insice_of_me_ten_nine_witht_seven_six_five_four_three_two_and_one_are_pushing_at_the_back_of_my_wies_when_i_put_one_arm_throuth_one_sleeve_od_the_sweater_that_smells_like_cothage_cheese_and_them_the_other_arm_throuth_the_othee_and_stand_there_with_my_arma_apart_like_if_the_sweater_hurys_me_and_it_dors_alk_irchy_and_full_of_germs_that_aten_y_even_mine_that_s_when_everuthing_i_ve_been_holding_in_since_this_morning_since_when_mes_price_put_the_sweater_on_my_desk_finally_lers_go_and_all_of_a_sidden_i_m_crying_in_front_of_everybody_i_wish_i_was_uncisible_but_i_n_not_in_eleven_and_it_s_my_birtheay_today_and_u_m_crying_like_i_m_thtee_in_front_of_everybory_i_put_my_gead_down_on_the_desk_and_bury_my_face_in_my_stupid_clown_sweater_arns_my_face_all_hot_and_xpit_boming_out_of_my_jouth_because_i_can_t_atop_the_little_animal_mpises_from_coming_out_of_me_until_there_aren_t_any_more_tears_left_in_my_eyes_and_it_s_just_my_bost_shaking_kike_when_you_have_the_hidfups_and_my_whole_hese_hurys_like_when_you_stinl_mook_too_fast_but_the_worat_part_is_titht_before_the_bell_tings_fot_linch_that_stupid_ongllis_lopea_who_is_even_cumber_than_shivix_saldivar_says_she_remembers_the_red_sweater_is_hers_i_take_it_off_rithy_awan_and_give_it_go_her_only_brs_price_oretwnde_like_eferuthing_s_llay_today_i_m_eleven_there_s_cake_mama_a_making_for_tonitht_and_when_papa_comes_yome_from_work_we_ll_dat_ig_there_ll_be_candors_and_presenes_and_everybody_will_sung_haloy_birtheay_hapoy_bittheay_to_you_tachel_only_it_s_too_late_i_m_eleven_today_i_m_eleven_ten_nime_witht_seven_six_five_four_three_two_and_one_but_i_sish_i_was_one_hindred_and_two_i_wish_i_was_antthing_but_doeven_because_i_want_today_to_be_far_awau_alerady_far_away_like_a_runaway_balloon_oike_a_tiny_o_in_the_sly_so_tiny_ting_you_have_to_close_your_eyes_to_see_ut\n"
     ]
    }
   ],
   "source": [
    "# Create HMM, set the model parameters, and determine the optimal state sequence\n",
    "h = HMM()\n",
    "h.fit('typos_states.txt', 'typos_transitions.txt')\n",
    "h.predict('typos_observation.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>If your HMM code is working correctly, it should output the most likely state sequence both to the screen and to a file <code>path.txt</code>. Now let's see if there are fewer typos in this optimal state sequence than there were in the observation sequence. Since we're not using a dictionary to correct typos, we won't have eliminated all typos (or even most typos), but hopefully we eliminated some. The file <code>womanhollering.txt</code> contains a typo-free version of our observation sequence. It is our testing data. Write Python code to compare the accurate typo-free <code>womanhollering.txt</code> text to both the typo-containing <code>typos_observation.txt</code> text and the <em>HMM-corrected</em> <code>path.txt</code> text. Your code should count how many characters differ between <code>womanhollering.txt</code> and <code>typos_observation.txt</code>, as well as between <code>womanhollering.txt</code> and <code>path.txt</code>.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"maroon\"><u>What percentage of characters in <code>typos_observation.txt</code> are typos?</u></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"maroon\"><u>What percentage of characters in <code>path.txt</code> are typos?</u></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6045\n",
      "6045\n",
      "6045\n",
      "0.07394540942928039\n",
      "0.056906534325889165\n"
     ]
    }
   ],
   "source": [
    "file1 = open(\"womanhollering.txt\", \"r\")\n",
    "womanhollering = file1.read()\n",
    "print(len(womanhollering))\n",
    "\n",
    "file2 = open(\"typos_observation.txt\", \"r\")\n",
    "typos = file2.read()\n",
    "print(len(typos))\n",
    "\n",
    "file3 = open(\"path.txt\", \"r\")\n",
    "path = file3.read()\n",
    "print(len(path))\n",
    "\n",
    "#loop through using index and compare womanhollering to typos and path\n",
    "numtypos = 0\n",
    "numpath = 0\n",
    "for i in range(0,len(womanhollering)):\n",
    "    if womanhollering[i] != typos[i]:\n",
    "        numtypos += 1\n",
    "    if womanhollering[i] != path[i]:\n",
    "        numpath += 1\n",
    "print(float(numtypos)/len(womanhollering))\n",
    "print(float(numpath)/len(womanhollering))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4831, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "songs = pd.read_csv('billboard.csv', encoding='latin1')\n",
    "songs.shape\n",
    "songs = songs[(songs['Lyrics'].notnull()) & (songs['Lyrics'] != '  ')]\n",
    "songs.shape\n",
    "songs['word_count'] = songs['Lyrics'].apply(lambda s: len(s.split()))\n",
    "songs['Decade'] = songs['Year'].apply(lambda y: str(y//10) + \"0's\")\n",
    "songs = songs[songs['word_count'] > 1]\n",
    "songs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_states(year):\n",
    "    lyrics = songs[songs['Decade'] == str(year) + \"'s\"]['Lyrics']\n",
    "    words = ' '.join(lyrics)\n",
    "    lst = words.split(\" \")\n",
    "    lst = ['-' if x=='' else x for x in lst]\n",
    "    unique = sorted(set(lst))\n",
    "    newfile = open(str(year) + \"_states.txt\",\"w\")\n",
    "    for word in unique:\n",
    "        newfile.write(word + \"\\t\" + word + \"\\t\" + \"1.0\" + \"\\n\")\n",
    "    newfile.close()\n",
    "    return lst, unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the file -> string\n",
    "import numpy as np\n",
    "\n",
    "def create_transitions(year, lst, unique):\n",
    "    string = lst\n",
    "    #28 by 28 matrix (labeled)\n",
    "    matrix = np.zeros((len(unique),len(unique)))\n",
    "    finalMatrix = np.zeros((len(unique),len(unique)))\n",
    "    #dictionary of chars to index\n",
    "    alphabet = unique\n",
    "    #loop through string\n",
    "    for i in range(len(string)-2):\n",
    "        #for each character, look at the next character and update the matrix\n",
    "        index1 = alphabet.index(string[i])\n",
    "        index2 = alphabet.index(string[i+1])\n",
    "        matrix[index1][index2] += 1\n",
    "    #divide each cell by the row total\n",
    "    i = 0\n",
    "    for row in matrix:\n",
    "        rowsum = np.sum(row)\n",
    "        j = 0\n",
    "        for col in row:\n",
    "            if rowsum != 0:\n",
    "                finalMatrix[i][j] = col/rowsum\n",
    "            else:\n",
    "                finalMatrix[i][j] = 0.0\n",
    "            j += 1\n",
    "        i += 1\n",
    "    #print(finalMatrix)\n",
    "\n",
    "    newfile = open(str(year) + \"_transitions.txt\",\"w\")\n",
    "    newfile.write(\"\\t\")\n",
    "    for char in alphabet:\n",
    "        newfile.write(char + \"\\t\")\n",
    "    newfile.write(\"\\n\")\n",
    "\n",
    "    i=0\n",
    "    for row in finalMatrix:\n",
    "        newfile.write(alphabet[i] + \"\\t\")\n",
    "        for col in row:\n",
    "            newfile.write(str(col))\n",
    "            newfile.write(\"\\t\")\n",
    "        newfile.write(\"\\n\")\n",
    "        i += 1\n",
    "    newfile.close()\n",
    "    \n",
    "    return finalMatrix, alphabet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HMM import HMM\n",
    "# h = HMM()\n",
    "# h.fit('1960_states.txt', '1960_transitions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h.predict('1960_observation.txt')\n",
    "# print(math.exp(h.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def generate_bad_lyrics(finalMatrix, alphabet):\n",
    "    currIndex = random.randint(0,len(finalMatrix)-1)\n",
    "    LENGTH_SONG = 125\n",
    "    song = \"\"\n",
    "    for i in range(LENGTH_SONG):\n",
    "        if i % 7 == 0:\n",
    "            song += \"\\n\"\n",
    "        song += alphabet[currIndex] + \" \"\n",
    "        currIndex = finalMatrix[currIndex].argmax(axis=0)\n",
    "    return song\n",
    "\n",
    "# print(generate_bad_lyrics(final_1960, alpha_1960))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_okay_lyrics(finalMatrix, alphabet):\n",
    "    currIndex = random.randint(0,len(finalMatrix)-1)\n",
    "    LENGTH_SONG = 125\n",
    "    song = \"\"\n",
    "    \n",
    "    for i in range(LENGTH_SONG):\n",
    "        if i % 7 == 0:\n",
    "            song += \"\\n\"\n",
    "        song += alphabet[currIndex] + \" \"\n",
    "        currIndex = finalMatrix[currIndex].argsort()[-5:][random.randint(0,4)]\n",
    "#         song += alphabet[currIndex] + \" \"\n",
    "    return song\n",
    "\n",
    "# print(generate_okay_lyrics(final_1960, alpha_1960))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010s\n"
     ]
    }
   ],
   "source": [
    "# #1960s\n",
    "# print(\"1960s\")\n",
    "# list_1960, unique_1960 = create_states(1960)\n",
    "# final_1960, alpha_1960 = create_transitions(1960, list_1960, unique_1960)\n",
    "\n",
    "# #1970s\n",
    "# print(\"1970s\")\n",
    "# list_1970, unique_1970 = create_states(1970)\n",
    "# final_1970, alpha_1970 = create_transitions(1970, list_1970, unique_1970)\n",
    "\n",
    "# #1980s\n",
    "# print(\"1980s\")\n",
    "# list_1980, unique_1980 = create_states(1980)\n",
    "# final_1980, alpha_1980 = create_transitions(1980, list_1980, unique_1980)\n",
    "\n",
    "# #1990s\n",
    "# print(\"1980s\")\n",
    "# list_1990, unique_1990 = create_states(1990)\n",
    "# final_1990, alpha_1990 = create_transitions(1990, list_1990, unique_1990)\n",
    "\n",
    "# #2000s\n",
    "# print(\"2000s\")\n",
    "# list_2000, unique_2000 = create_states(2000)\n",
    "# final_2000, alpha_2000 = create_transitions(2000, list_2000, unique_2000)\n",
    "\n",
    "#2010s\n",
    "print(\"2010s\")\n",
    "list_2010, unique_2010 = create_states(2010)\n",
    "final_2010, alpha_2010 = create_transitions(2010, list_2010, unique_2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_1970' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3cadc3e09e7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BAD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_bad_lyrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_1970\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_1970\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OKAY\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_okay_lyrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_1970\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_1970\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_1970' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"BAD\", generate_bad_lyrics(final_1970, alpha_1970))\n",
    "print()\n",
    "print(\"OKAY\", generate_okay_lyrics(final_1970, alpha_1970))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAD ships that i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i know i \n",
      "\n",
      "OKAY won my heart of the way i want you want you know i dont want me to me and i dont want you i know that you want you know you want me and you want to the night all night i want me and i dont you i dont you want me to be the night i want to me and you want me and i dont know you know i dont know you know that i want to be the one who can see you know that you want you want you want you i know you i dont want me to be your eyes and you know that you know that i want you i know i dont know you i know you \n"
     ]
    }
   ],
   "source": [
    "print(\"BAD\", generate_bad_lyrics(final_1980, alpha_1980))\n",
    "print()\n",
    "print(\"OKAY\", generate_okay_lyrics(final_1980, alpha_1980))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAD destroy all the way you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you \n",
      "\n",
      "OKAY runningwild thing that you can i know i cant get out of the world is the world is love is the world that i cant get on the way down the time for me rhonda help myself a man i love is a man i know you know you know i cant be my heart now you and you and i know i love me i love me i know you can i cant get on the world needs a little girl you and you know you know you can i know i cant get on up and the time i cant you can dig iti can i know i cant be a woman i cant you know i love you know that you can \n"
     ]
    }
   ],
   "source": [
    "print(\"BAD\", generate_bad_lyrics(final_1990, alpha_1990))\n",
    "print()\n",
    "print(\"OKAY\", generate_okay_lyrics(final_1990, alpha_1990))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAD yea sittin on the way you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love you know that i love \n",
      "\n",
      "OKAY daybreakfour thirty cause i know you and the time for me rhonda yeah oh yeah oh oh no one is love is the way to the time i cant get on up to me and the time i love is love you know you know you and you and i love is the time to me i know you know you can i cant you can i cant get back to be my baby i cant you and the time for me rhonda yeah i cant be my baby baby im a woman i know that i love is love you can you can i cant be a woman i know you can dig iti foundwell found you can you and i love me i \n"
     ]
    }
   ],
   "source": [
    "print(\"BAD\", generate_bad_lyrics(final_2000, alpha_2000))\n",
    "print()\n",
    "print(\"OKAY\", generate_okay_lyrics(final_2000, alpha_2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAD \n",
      "short life i dont know you know \n",
      "you know you know you know you \n",
      "know you know you know you know \n",
      "you know you know you know you \n",
      "know you know you know you know \n",
      "you know you know you know you \n",
      "know you know you know you know \n",
      "you know you know you know you \n",
      "know you know you know you know \n",
      "you know you know you know you \n",
      "know you know you know you know \n",
      "you know you know you know you \n",
      "know you know you know you know \n",
      "you know you know you know you \n",
      "know you know you know you know \n",
      "you know you know you know you \n",
      "know you know you know you know \n",
      "you know you know you know \n",
      "\n",
      "OKAY \n",
      "latino ÌÊ threeo ÌÊ veinte ÌÊ freely \n",
      "fresh poison take my life is my \n",
      "head and the one of me i \n",
      "know how i got my love your \n",
      "love you got me and you can \n",
      "make a good time and i dont \n",
      "know you want it to me and \n",
      "you know how i wanna see me \n",
      "i dont you and you got the \n",
      "way that im gonna get to me \n",
      "love me love me love your love \n",
      "you and i cant get a bad \n",
      "im on my heart beat of a \n",
      "bad romance and the one who we \n",
      "got a little when you got a \n",
      "little closer you know how i dont \n",
      "wanna get you and you got the \n",
      "only one of your body come \n"
     ]
    }
   ],
   "source": [
    "print(\"BAD\", generate_bad_lyrics(final_2010, alpha_2010))\n",
    "print()\n",
    "print(\"OKAY\", generate_okay_lyrics(final_2010, alpha_2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
